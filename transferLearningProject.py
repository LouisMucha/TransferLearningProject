# -*- coding: utf-8 -*-
"""transfer-learning-with-xception-for-cifar-10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vWReHeh8KoHFHJkuyW66mEaezWyxHy-e

# Apprentissage par transfert avec les réseaux de neurones profonds
"""

!pip install tensorflow

"""# Load Required Modules"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import numpy as np
import pandas as pd

import warnings
warnings.filterwarnings("ignore")

#Import keras functions

import tensorflow as tf
print(tf.__version__)

from sklearn.model_selection import train_test_split
from keras import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import SGD,Adam
from keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.applications import VGG19,Xception
from tensorflow.keras.layers import Input,Flatten,Dense,Conv2D,BatchNormalization,Activation,Dropout,GlobalAveragePooling2D,AveragePooling2D,MaxPooling2D,RandomFlip,RandomZoom,RandomRotation

#Import the dataset

from keras.datasets import cifar10

"""# Load CIFAR-10"""

(x_train, y_train), (x_val, y_val)= cifar10.load_data()

x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

y_train=to_categorical(y_train)
y_test=to_categorical(y_test)
y_val=to_categorical(y_val)

print((x_train.shape, y_train.shape))
print((x_test.shape, y_test.shape))
print((x_val.shape, y_val.shape))

"""# Xception"""

base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3), classes=y_train.shape[1])

"""Bloque l'entrainement de la couche du model Xception"""

# freeze all layers
base_model.trainable = False

data_augmentation = Sequential(
    [RandomFlip("horizontal"),
     RandomRotation(0.1),
     RandomZoom(0.1)]
)

"""
La résolution d'origine de CIRFAR-10 est 32x32 elle est trop faible pour Xception que necessite au minima 71x71"""

inputs = tf.keras.Input(shape=(32, 32, 3))
x = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (224,224)))(inputs)
x = data_augmentation(x)
x = tf.keras.applications.xception.preprocess_input(x)
x = base_model(x, training=False)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.3)(x)
outputs = tf.keras.layers.Dense(10, activation=('softmax'))(x)
model = tf.keras.Model(inputs, outputs)

#Check the architecture of the final model

model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

epochs = 10

history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, verbose=1)

model.save('/content/trainedModel.h5')

#model = tf.keras.models.load_model('/content/trainedModel.h5')

loss, accuracy = model.evaluate(x_test,y_test, verbose=2)

print(f"Perte (Loss) sur l'ensemble de test: {loss}")
print(f"Précision (Accuracy) sur l'ensemble de test: {accuracy}")

"""## Cross Validation pour le model par transfert


"""

def plot_history(history,s):
    history_frame = pd.DataFrame(history.history)
    TempLoss = history_frame.loc[:, ['loss', 'val_loss']].plot()
    TempLoss.set_title(s+" - loss & val_loss")


    TempAcc = history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()
    TempAcc.set_title(s+" - accuracy & val_accuracy pour ")

    return

plot_history(history,"transfer learning")

"""# A Simple CNN from scratch

"""

#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

modelCnn = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D(2, 2),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Flatten(),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ])

modelCnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn = modelCnn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, verbose=1)

loss, accuracy = modelCnn.evaluate(x_test,y_test, verbose=2)
print(f"Perte (Loss) sur l'ensemble de test: {loss}")
print(f"Précision (Accuracy) sur l'ensemble de test: {accuracy}")

modelCnn.summary()

"""## Cross Validation pour le CNN simple

"""

plot_history(cnn,"CNN")

"""# Confusion Matrix pour le CNN simple

"""

class_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

predictions=modelCnn.predict(x_val)

y_pred_classes = np.argmax(predictions, axis=1)
y_true = np.argmax(y_val, axis=1)

confusion_mtx = y_val.shape[1]*tf.math.confusion_matrix(y_true, y_pred_classes)/y_val.shape[0]

plt.figure(figsize=(12, 9))
c = sns.heatmap(confusion_mtx, annot=True, fmt='g')
c.set(xticklabels=class_names, yticklabels=class_names)
plt.title("CNN - Matrice de confusion")

"""# Confusion Matrix pour le model de transfert"""

predictions=model.predict(x_val)

y_pred_classes = np.argmax(predictions, axis=1)
y_true = np.argmax(y_val, axis=1)

confusion_mtx = y_val.shape[1]*tf.math.confusion_matrix(y_true, y_pred_classes)/y_val.shape[0]

plt.figure(figsize=(12, 9))
c = sns.heatmap(confusion_mtx, annot=True, fmt='g')
c.set(xticklabels=class_names, yticklabels=class_names)
plt.title("Transfer Learning - Matrice de confusion")

"""# Autre Architecture de CNN_2"""

#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

modelCnn_2 = Sequential([
            Conv2D(32, (3, 3), activation='sigmoid', input_shape=(32, 32, 3)),
            MaxPooling2D(2, 2),
            Flatten(),
            Dropout(0.3),
            Dense(256, activation='relu'),
            Dense(10, activation='softmax')
        ])

modelCnn_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn_2 = modelCnn_2.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, verbose=1)

loss, accuracy = modelCnn_2.evaluate(x_test,y_test, verbose=2)
print(f"Perte (Loss) sur l'ensemble de test: {loss}")
print(f"Précision (Accuracy) sur l'ensemble de test: {accuracy}")

plot_history(cnn_2,"CNN_2")

predictions=modelCnn_2.predict(x_val)

y_pred_classes = np.argmax(predictions, axis=1)
y_true = np.argmax(y_val, axis=1)

confusion_mtx = y_val.shape[1]*tf.math.confusion_matrix(y_true, y_pred_classes)/y_val.shape[0]

plt.figure(figsize=(12, 9))
c = sns.heatmap(confusion_mtx, annot=True, fmt='g')
c.set(xticklabels=class_names, yticklabels=class_names)
plt.title("CNN_2 - Matrice de confusion")

"""# Autre Architecture de CNN_3"""

#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

modelCnn_3 = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D(2, 2),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Flatten(),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ])

modelCnn_3.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

cnn_3 = modelCnn_3.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, verbose=1)

loss, accuracy = modelCnn_3.evaluate(x_test,y_test, verbose=2)
print(f"Perte (Loss) sur l'ensemble de test: {loss}")
print(f"Précision (Accuracy) sur l'ensemble de test: {accuracy}")

plot_history(cnn_3,"CNN_3")

predictions=modelCnn_3.predict(x_val)

y_pred_classes = np.argmax(predictions, axis=1)
y_true = np.argmax(y_val, axis=1)

confusion_mtx = y_val.shape[1]*tf.math.confusion_matrix(y_true, y_pred_classes)/y_val.shape[0]

plt.figure(figsize=(12, 9))
c = sns.heatmap(confusion_mtx, annot=True, fmt='g')
c.set(xticklabels=class_names, yticklabels=class_names)
plt.title("CNN_3 - Matrice de confusion")

"""# Autre architecture CNN_4"""

#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

modelCnn_4 = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D(2, 2),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Flatten(),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dense(10, activation='softmax')
        ])

modelCnn_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn_4 = modelCnn_4.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=64, epochs=epochs, verbose=1)

loss, accuracy = modelCnn_4.evaluate(x_test,y_test, verbose=2)
print(f"Perte (Loss) sur l'ensemble de test: {loss}")
print(f"Précision (Accuracy) sur l'ensemble de test: {accuracy}")

plot_history(cnn_4,"CNN_4")

predictions=modelCnn_4.predict(x_val)

y_pred_classes = np.argmax(predictions, axis=1)
y_true = np.argmax(y_val, axis=1)

confusion_mtx = y_val.shape[1]*tf.math.confusion_matrix(y_true, y_pred_classes)/y_val.shape[0]

plt.figure(figsize=(12, 9))
c = sns.heatmap(confusion_mtx, annot=True, fmt='g')
c.set(xticklabels=class_names, yticklabels=class_names)
plt.title("CNN_4 - Matrice de confusion")